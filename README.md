<img width="1920" height="1020" alt="Screenshot 2025-12-02 224026" src="https://github.com/user-attachments/assets/7702e9bb-4cf1-4f79-ba1b-d2e1b12a34e3" /># NeuroNova ‚Äî conversational emotion visualization (prototype)



**Author:** Mahesh  
**Project:** NeuroNova semantic visual demo  
**Purpose:** Small research/demo tool that converts text inputs into an emotion activation heatmap, lightweight spiking-LIF simulation, and simple response templates. Intended for academic demonstration only.

> ‚ö†Ô∏è **Important safety note:** This project contains a non-clinical heuristic model that estimates emotion and a simple mental-health risk score. It is experimental and **not** a medical or diagnostic tool. If a user is in immediate danger or exhibiting self-harm intent, follow local emergency protocols and contact professional services.

<p>This prototype was created during my independent study on human-centered AI and neural activation visualization. It helped me explore how spiking models and semantic detectors can be combined for interaction research </p>
---

## What's included

- `neuronova/engine.py` ‚Äî core semantic detector +
 LIF spiking population + response generator.
- `neuronova/visualizer.py` ‚Äî matplotlib visualization helpers (interactive and non-interactive modes).
- `neuronova/cli.py` ‚Äî command-line interface.
- `neuronova/config.py` ‚Äî configuration and environment variables.
- `examples/demo_noninteractive.py` ‚Äî runs three example inputs and saves static PNG outputs to `assets/`.
- `assets/` ‚Äî pre-generated screenshots and sample images.
- `requirements.txt` ‚Äî Python packages required.

---

## üìä Visual Output

Here are sample visualizations generated by the system:

<img width="1920" height="1020" alt="Screenshot 2025-12-02 224154" src="https://github.com/user-attachments/assets/38a6ccb9-0e52-46f9-a9b4-4d4b67078c3a" />
<img width="1920" height="1020" alt="Screenshot 2025-12-02 224026" src="https://github.com/user-attachments/assets/229e6b31-3163-43a6-9906-2899fcecb60b" />

The visualizations show:
- **Emotion activation heatmap** ‚Äî Real-time emotion detection across 27 emotions
- **Mental health risk assessment** ‚Äî Risk score tracking over conversation turns
- **Neural firing rates** ‚Äî Spiking neural network activity over time
- **Membrane potentials** ‚Äî Individual neuron voltage traces showing spiking behavior

---

## Quick start (non-interactive demo)

1. Create a virtual environment (recommended):
   ```bash
   python3 -m venv venv
   source venv/bin/activate 
   pip install -r requirements.txt
   ```

2. Run demo (writes outputs to assets/):
   ```bash
   python examples/demo_noninteractive.py
   ```

3. Inspect `assets/screenshot1.png`, `assets/screenshot2.png`, and `assets/transcript.txt`.

---

## Optional interactive mode

If you want to try interactive graphs, run:

```bash
python -m neuronova.cli
```

Then at the prompt type sentences or `graph` to open the conversation graph. (Interactive plotting requires a GUI-enabled environment.)

---

## Configuration & Security

- `GEMINI_API_KEY` or `OPENAI_API_KEY` can be set as environment variables if you want remote LLM fallback (optional).
- To disable remote API usage for privacy, do not set those environment variables.
- By default, the system will not send any user input to remote APIs unless explicitly configured.

---

## Ethical considerations

- The mental-health detection is heuristic and may produce false positives/negatives.
- Do not deploy as a clinical tool.
- The insult word list in `data/insult_words.txt` is used only for detection purposes. Remove or restrict if distributing in contexts where offensive terms are not acceptable.

---

## License

MIT ‚Äî see LICENSE file.

---

<h4>In the future, I plan to extend this system with explainable AI modules and improved temporal modeling</h4>

## Contact

If you'd like to discuss the methodology or see a live walkthrough,
you can reach me at:

Email: mahesh9880302264.v@gmail.com
LinkedIn: https://www.linkedin.com/in/mr-mahesh-4209b4284


